# Customized MediaPipe face mesh rendering subgraph.
type: "FaceRendererGpu"

# GPU image. (GpuBuffer)
input_stream: "IMAGE:input_image"

# Regions of interest calculated based on face detections.
# (std::vector<NormalizedRect>)
input_stream: "NORM_RECTS:rects"

# Multi-face Alignment data
# (std::vector<std::map<std::string, double>>)
input_stream: "ALIGNMENTS:multi_face_alignments"

# Multi-face blink data
# (std::vector<std::map<std::string, double>>)
input_stream: "BLINKS:multi_face_blinks"

# GPU image with rendered data. (GpuBuffer)
output_stream: "IMAGE:output_image"

# Calculate image properties
node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE_GPU:input_image"
  output_stream: "SIZE:image_size"
}

# Convert the FaceAlignment to RenderData
node {
  calculator: "FaceAlignmentToRenderDataCalculator"
  input_stream: "ALIGNMENT:multi_face_alignments"
  output_stream: "RENDER:alignment_render_data"
}

# Converts detected eye blinks to drawing primitives for annotation overlay.
node {
  calculator: "EyeBlinkToRenderDataCalculator"
  input_stream: "BLINK:multi_face_blinks"
  output_stream: "RENDER:blink_render_data"
}

# Converts normalized rects to drawing primitives for annotation overlay.
node {
  calculator: "RectToRenderDataCalculator"
  input_stream: "NORM_RECTS:rects"
  output_stream: "RENDER_DATA:rects_render_data"
  node_options: {
    [type.googleapis.com/mediapipe.RectToRenderDataCalculatorOptions] {
      filled: false
      color { r: 255 g: 0 b: 0 }
      thickness: 4.0
    }
  }
}

# Draws annotations and overlays them on top of the input images.
node {
  calculator: "AnnotationOverlayCalculator"
  input_stream: "IMAGE_GPU:input_image"
  input_stream: "alignment_render_data"
  input_stream: "blink_render_data"
  input_stream: "rects_render_data"
  output_stream: "IMAGE_GPU:output_image"
}
